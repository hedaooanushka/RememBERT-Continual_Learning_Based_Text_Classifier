{"cells":[{"cell_type":"markdown","metadata":{},"source":["## INITIALIZE LOGGER"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-23T19:12:01.893225Z","iopub.status.busy":"2024-05-23T19:12:01.892601Z","iopub.status.idle":"2024-05-23T19:12:05.060401Z","shell.execute_reply":"2024-05-23T19:12:05.059484Z","shell.execute_reply.started":"2024-05-23T19:12:01.893190Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["import wandb\n","wandb.login(key=\"3db31cd19d063689e924d07069de6c7a1670642b\") "]},{"cell_type":"markdown","metadata":{},"source":["## IMPORTS"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-23T19:11:46.220044Z","iopub.status.busy":"2024-05-23T19:11:46.219645Z","iopub.status.idle":"2024-05-23T19:11:50.061093Z","shell.execute_reply":"2024-05-23T19:11:50.059561Z","shell.execute_reply.started":"2024-05-23T19:11:46.220013Z"},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'avalanche'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mavalanche\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbenchmarks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AvalancheDataset\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mavalanche\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbenchmarks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nc_benchmark\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'avalanche'"]}],"source":["import os\n","import json\n","import math\n","from collections import OrderedDict\n","import torch\n","from torch import nn, Tensor\n","from typing import Union, Tuple, List, Iterable, Dict\n","import torch.nn.functional as F\n","from torch.nn.parameter import Parameter\n","from torch.optim import AdamW\n","from torch.utils.data import DataLoader\n","import numpy as np\n","import gzip, csv\n","import pandas as pd\n","from tqdm.auto import tqdm\n","import torch.nn.init as init\n","from sklearn.metrics import f1_score\n","import random\n","torch.manual_seed(0)\n","np.random.seed(0)\n","from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","import argparse\n","import torch\n","from torch.nn import CrossEntropyLoss\n","from torch.optim import AdamW\n","from torch import nn, Tensor\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset\n","from avalanche.benchmarks.utils import AvalancheDataset\n","from avalanche.benchmarks.generators import nc_benchmark\n","from transformers import BertTokenizer\n","from datasets import load_dataset\n","import re\n","from avalanche.benchmarks.classic import SplitMNIST\n","from avalanche.models import MTSimpleMLP\n","from avalanche.training.supervised import EWC\n","from avalanche.evaluation.metrics import forgetting_metrics, accuracy_metrics\n","from avalanche.logging import InteractiveLogger\n","from avalanche.training.plugins import EvaluationPlugin\n","from avalanche.evaluation.metrics import forgetting_metrics, accuracy_metrics, \\\n","    loss_metrics, timing_metrics, cpu_usage_metrics, confusion_matrix_metrics, disk_usage_metrics\n","from avalanche.training.templates import SupervisedTemplate\n","from avalanche.training.plugins import ReplayPlugin, EWCPlugin\n","from avalanche.logging import WandBLogger\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"markdown","metadata":{},"source":["## ACTIVATION FUNCTION"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T18:53:57.453573Z","iopub.status.busy":"2024-05-22T18:53:57.452787Z","iopub.status.idle":"2024-05-22T18:53:57.459768Z","shell.execute_reply":"2024-05-22T18:53:57.458333Z","shell.execute_reply.started":"2024-05-22T18:53:57.453541Z"},"trusted":true},"outputs":[],"source":["def gelu(x):\n","    \"\"\"Implementation of the gelu activation function.\"\"\"\n","    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n"]},{"cell_type":"markdown","metadata":{},"source":["## POSTIONAL ENCODING LAYER"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T18:53:58.037034Z","iopub.status.busy":"2024-05-22T18:53:58.036086Z","iopub.status.idle":"2024-05-22T18:53:58.047263Z","shell.execute_reply":"2024-05-22T18:53:58.045786Z","shell.execute_reply.started":"2024-05-22T18:53:58.036995Z"},"trusted":true},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","\n","    def __init__(self, embed_dim: int, drop_rate=0.1, max_len=5000):\n","        super().__init__()\n","        self.dropout = nn.Dropout(p=drop_rate)\n","\n","        position = torch.arange(max_len).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, embed_dim, 2) * (-math.log(10000.0) / embed_dim))\n","        pe = torch.zeros(1, max_len, embed_dim)\n","        pe[0, :, 0::2] = torch.sin(position * div_term)\n","        pe[0, :, 1::2] = torch.cos(position * div_term)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Args:\n","            x: Tensor, shape [batch_size, seq_len, embedding_dim]\n","        \n","        Returns:\n","            torch.Tensor: Output tensor after adding positional encodings and applying dropout.\n","                 It has the same shape as the input tensor [batch_size, seq_len, embedding_dim].\n","                 The positional encodings are added to the input tensor along the sequence length dimension,\n","                 and dropout is applied to the combined tensor.\n","        \n","        \"\"\"\n","        x = x + self.pe[:, :x.size(1)]\n","        return self.dropout(x)"]},{"cell_type":"markdown","metadata":{},"source":["## ATTENTION MECHANISM"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T18:53:58.598367Z","iopub.status.busy":"2024-05-22T18:53:58.597927Z","iopub.status.idle":"2024-05-22T18:53:58.606770Z","shell.execute_reply":"2024-05-22T18:53:58.605577Z","shell.execute_reply.started":"2024-05-22T18:53:58.598334Z"},"trusted":true},"outputs":[],"source":["def scaled_dot_product(q, k, v, attn_drop_rate=0.1):\n","    \"\"\"\n","    Args:\n","      q: query, shape: (batch, # heads, seq len, head dimension)\n","      k: keys, shape: (batch, # heads, seq len, head dimension)\n","      v: value, shape: (batch, # heads, seq len, head dimension)\n","      attn_drop_rate: probability of an element to be zeroed,\n","      mask: the optional masking of specific entries in the attention matrix.\n","              shape: (batch, seq len)\n","    \n","     Returns:\n","        torch.Tensor: Output tensor after scaled dot product attention computation.\n","           Shape: (batch, # heads, seq len, head dimension).\n","    \n","    \"\"\"\n","    d_k = q.shape[-1]\n","    attn_logits = torch.matmul(q, k.transpose(-1, -2))\n","    attn_logits = attn_logits/math.sqrt(d_k)\n","    attention = F.softmax(attn_logits, dim=-1)\n","    attention = F.dropout(attention, p=attn_drop_rate)\n","    values = torch.matmul(attention,v)\n","    return values"]},{"cell_type":"markdown","metadata":{},"source":["### MULTI HEAD SELF ATTENTION"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T18:53:59.147730Z","iopub.status.busy":"2024-05-22T18:53:59.147303Z","iopub.status.idle":"2024-05-22T18:53:59.165738Z","shell.execute_reply":"2024-05-22T18:53:59.164414Z","shell.execute_reply.started":"2024-05-22T18:53:59.147695Z"},"trusted":true},"outputs":[],"source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, embed_dim, n_heads, attn_drop_rate):\n","        super().__init__()\n","        self.embed_dim = embed_dim\n","        self.n_heads = n_heads\n","        self.head_dim = embed_dim // n_heads\n","        self.attn_drop_rate = attn_drop_rate\n","        self.query = nn.Linear(self.embed_dim, self.n_heads*self.head_dim)\n","        self.key = nn.Linear(self.embed_dim, self.n_heads*self.head_dim)\n","        self.value = nn.Linear(self.embed_dim, self.n_heads*self.head_dim)\n","        self.o_proj = nn.Linear(self.embed_dim, self.n_heads*self.head_dim)\n","        self._reset_parameters()\n","\n","    def _reset_parameters(self):\n","      nn.init.xavier_uniform_(self.query.weight)\n","      self.query.bias.data.fill_(0)\n","      nn.init.xavier_uniform_(self.key.weight)\n","      self.key.bias.data.fill_(0)\n","      nn.init.xavier_uniform_(self.value.weight)\n","      self.value.bias.data.fill_(0)\n","      nn.init.xavier_uniform_(self.o_proj.weight)\n","      self.o_proj.bias.data.fill_(0)\n","\n","    def split_heads(self, tensor):\n","       new_shape = tensor.size()[:-1] + (self.n_heads, self.head_dim)\n","       tensor = tensor.view(*new_shape)\n","       tensor = tensor.permute(0, 2, 1, 3).contiguous()\n","       return tensor\n","\n","    def merge_heads(self, tensor, batch_size, seq_length):\n","       tensor = tensor.transpose(1, 2).contiguous().view(batch_size, seq_length, self.embed_dim)\n","       return tensor\n","\n","    def forward(self, embedding):\n","      \"\"\"\n","       Args:\n","        embedding (torch.Tensor): \n","            A tensor of shape (batch_size, seq_length, embed_dim) representing the input embeddings.\n","            - `batch_size`: The number of samples in the batch.\n","            - `seq_length`: The number of tokens (or time steps) in each sequence.\n","            - `embed_dim`: The dimension of the embedding for each token.\n","       \n","       Returns:\n","        torch.Tensor: \n","            A tensor of shape (batch_size, seq_length, embed_dim) representing the attended embeddings.\n","            - `batch_size`: The number of samples in the batch.\n","            - `seq_length`: The number of tokens (or time steps) in each sequence.\n","            - `embed_dim`: The dimension of the embedding for each token.\n","      \n","      \"\"\"\n","      batch_size, seq_length, embed_dim = embedding.size()\n","      q, k, v = self.query(embedding), self.key(embedding), self.value(embedding)\n","      q = self.split_heads(q)\n","      k = self.split_heads(k)\n","      v = self.split_heads(v)\n","      values = scaled_dot_product(q, k, v, self.attn_drop_rate)\n","      values = self.merge_heads(values, batch_size, seq_length)\n","      attended_embeds = self.o_proj(values)\n","      return attended_embeds"]},{"cell_type":"markdown","metadata":{},"source":["### MULTI HEAD CROSS ATTENTION"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T18:53:59.646499Z","iopub.status.busy":"2024-05-22T18:53:59.645317Z","iopub.status.idle":"2024-05-22T18:53:59.660337Z","shell.execute_reply":"2024-05-22T18:53:59.658974Z","shell.execute_reply.started":"2024-05-22T18:53:59.646459Z"},"trusted":true},"outputs":[],"source":["class MultiHeadCrossAttention(nn.Module):  \n","    def __init__(self, embed_dim, n_heads, attn_drop_rate):\n","        super().__init__()\n","        self.embed_dim = embed_dim\n","        self.n_heads = n_heads\n","        self.head_dim = embed_dim // n_heads\n","        self.key = nn.Linear(self.embed_dim, self.n_heads*self.head_dim)\n","        self.value = nn.Linear(self.embed_dim, self.n_heads*self.head_dim)\n","        self.query = nn.Linear(self.embed_dim , embed_dim)\n","        self.linear_layer = nn.Linear(embed_dim, embed_dim)\n","        self.attn_drop_rate = attn_drop_rate\n","   \n","    def forward(self, x, catx): \n","         \"\"\"\n","            Args:\n","             catx (torch.Tensor): \n","                 A tensor of shape (batch_size, seq_length, embed_dim) representing the input embeddings of orignal sequence with additional context.\n","                 - `batch_size`: The number of samples in the batch.\n","                 - `seq_length`: The number of tokens (or time steps) in each sequence.\n","                 - `embed_dim`: The dimension of the embedding for each token.\n","            \n","             x (torch.Tensor): \n","                 A tensor of shape (batch_size, seq_length, embed_dim) representing the input embeddings of orignal sequence.\n","                 - `batch_size`: The number of samples in the batch.\n","                 - `seq_length`: The number of tokens (or time steps) in each sequence.\n","                 - `embed_dim`: The dimension of the embedding for each token.     \n","                 \n","            Returns:\n","             torch.Tensor: \n","                 A tensor of shape (batch_size, seq_length, embed_dim) representing the attended embeddings.\n","                 - `batch_size`: The number of samples in the batch.\n","                 - `seq_length`: The number of tokens (or time steps) in each sequence.\n","                 - `embed_dim`: The dimension of the embedding for each token.\n","        \n","        \"\"\"\n","         qbatch_size, qsequence_length, qembeddings = x.size()\n","         batch_size, sequence_length, embeddings = catx.size()\n","         q, k, v = self.query(x), self.key(catx), self.value(catx)\n","         k = k.reshape(batch_size, sequence_length, self.n_heads, self.head_dim)  \n","         v = v.reshape(batch_size, sequence_length, self.n_heads, self.head_dim)\n","         q = q.reshape(qbatch_size, qsequence_length, self.n_heads, self.head_dim) \n","         k = k.permute(0, 2, 1, 3) \n","         v = v.permute(0, 2, 1, 3)\n","         q = q.permute(0, 2, 1, 3) \n","         values = scaled_dot_product(q, k, v, self.attn_drop_rate) \n","         values = values.reshape(qbatch_size, qsequence_length, embeddings)\n","         out = self.linear_layer(values)  \n","         return out "]},{"cell_type":"markdown","metadata":{},"source":["## LAYER NORMALIZATION LAYER"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T18:54:00.154542Z","iopub.status.busy":"2024-05-22T18:54:00.154076Z","iopub.status.idle":"2024-05-22T18:54:00.165238Z","shell.execute_reply":"2024-05-22T18:54:00.163862Z","shell.execute_reply.started":"2024-05-22T18:54:00.154507Z"},"trusted":true},"outputs":[],"source":["class LayerNormalization(nn.Module):\n","    def __init__(self, parameters_shape, eps=1e-5):\n","        super().__init__()\n","        self.parameters_shape=parameters_shape\n","        self.eps=eps\n","        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n","        self.beta =  nn.Parameter(torch.zeros(parameters_shape))\n","\n","    def forward(self, inputs):\n","        \"\"\"\n","         Args:\n","         inputs (Tensor): Input tensor to normalize.\n","         \n","         Returns:\n","                torch.Tensor: Normalized tensor after applying layer normalization.\n","                 It has the same shape as the input tensor `(batch_size, *parameters_shape)`.\n","\n","        \"\"\"\n","        dims = [-(i + 1) for i in range(len(self.parameters_shape))]\n","        mean = inputs.mean(dim=dims, keepdim=True)\n","        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n","        std = (var + self.eps).sqrt()\n","        y = (inputs - mean) / std\n","        out = self.gamma * y  + self.beta\n","        return out"]},{"cell_type":"markdown","metadata":{},"source":["## FEEDFORWARD LAYER"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T18:54:00.716259Z","iopub.status.busy":"2024-05-22T18:54:00.715785Z","iopub.status.idle":"2024-05-22T18:54:00.725582Z","shell.execute_reply":"2024-05-22T18:54:00.724285Z","shell.execute_reply.started":"2024-05-22T18:54:00.716219Z"},"trusted":true},"outputs":[],"source":["class PositionwiseFeedForward(nn.Module): \n","\n","    def __init__(self, embed_dim, drop_prob=0.1):\n","        super(PositionwiseFeedForward, self).__init__()\n","        self.linear1 = nn.Linear(embed_dim, 4*embed_dim)\n","        self.linear2 = nn.Linear(4*embed_dim, embed_dim)\n","        self.gelu = nn.GELU()\n","        self.dropout = nn.Dropout(p=drop_prob)\n","\n","    def forward(self, x):\n","        \"\"\"\n","         Args:\n","             x (torch.Tensor): Input tensor to the feedforward network.\n","                 Its shape should be `(batch_size, sequence_length, embed_dim)`.\n","                 `batch_size` is the number of sequences in a batch,\n","                 `sequence_length` is the length of each sequence,\n","                 and `embed_dim` is the dimensionality of the input and output embeddings.\n","     \n","         Returns:\n","             torch.Tensor: Output tensor of the feedforward network.\n","                 It has the same shape as the input tensor `(batch_size, sequence_length, embed_dim)`.\n","        \n","        \"\"\"\n","        x = self.linear1(x)\n","        x = self.gelu(x)\n","        x = self.dropout(x)\n","        x = self.linear2(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["## CLASSIFIER"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T18:54:01.332044Z","iopub.status.busy":"2024-05-22T18:54:01.331641Z","iopub.status.idle":"2024-05-22T18:54:01.339985Z","shell.execute_reply":"2024-05-22T18:54:01.338753Z","shell.execute_reply.started":"2024-05-22T18:54:01.332015Z"},"trusted":true},"outputs":[],"source":["class Classifier(nn.Module):\n","    def __init__(self, input_dim, numclasses, dropout_rate=0.1):\n","        super(Classifier, self).__init__()\n","        self.linear = nn.Linear(input_dim, numclasses) \n","\n","    def forward(self, x):\n","     \"\"\"\n","        Args:\n","            x (torch.Tensor): Input tensor to the classifier.\n","                Its shape should be `()`.\n","                `batch_size` is the number of samples in the batch,\n","                and `input_dim` is the dimensionality of the input features.\n","\n","        Returns:\n","            torch.Tensor: Output tensor representing the logits for each class.\n","                It has the shape `()`.\n","                `batch_size` is the number of samples in the batch,\n","                and `num_classes` is the number of classes in the classification task.\n","     \"\"\"\n","     x = self.linear(x)\n","     return x"]},{"cell_type":"markdown","metadata":{},"source":["## ENCODER LAYER"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T18:54:01.940835Z","iopub.status.busy":"2024-05-22T18:54:01.940410Z","iopub.status.idle":"2024-05-22T18:54:01.955821Z","shell.execute_reply":"2024-05-22T18:54:01.954492Z","shell.execute_reply.started":"2024-05-22T18:54:01.940801Z"},"trusted":true},"outputs":[],"source":["class EncoderLayer(nn.Module):\n","\n","    def __init__(self, embed_dim, n_heads, attn_drop_rate, layer_drop_rate):\n","        super(EncoderLayer, self).__init__()\n","        self.embed_dim = embed_dim\n","        self.n_heads = n_heads\n","        self.crossattention = MultiHeadCrossAttention(self.embed_dim, self.n_heads, attn_drop_rate)\n","        self.attention = MultiHeadAttention(self.embed_dim, self.n_heads, attn_drop_rate)\n","        self.norm1 = LayerNormalization(parameters_shape=[self.embed_dim])\n","        self.dropout1 = nn.Dropout(p=layer_drop_rate)\n","        self.ffn = PositionwiseFeedForward(self.embed_dim,layer_drop_rate)\n","        self.norm2 = LayerNormalization(parameters_shape=[self.embed_dim])\n","        self.dropout2 = nn.Dropout(p=layer_drop_rate)\n","\n","    def forward(self, catx, x=None, is_first=False):\n","        \"\"\"\n","            Args:\n","            catx (torch.Tensor): Input tensor to the encoder layer.\n","                Its shape should be `(batch_size, seq_length, embed_dim)`.\n","                - `batch_size`: The number of samples in the batch.\n","                - `seq_length`: The number of tokens (or time steps) in each sequence.\n","                - `embed_dim`: The dimension of the embedding for each token.\n","    \n","            x (torch.Tensor): Input tensor to the first encoder layer.\n","                Its shape should be `(batch_size, seq_length, embed_dim)`.\n","                - `batch_size`: The number of samples in the batch.\n","                - `seq_length`: The number of tokens (or time steps) in each sequence.\n","                - `embed_dim`: The dimension of the embedding for each token.\n","                \n","            \n","            Returns:\n","                torch.Tensor: Output tensor representing the encoded representations.\n","                    It has the same shape as the input tensor `(batch_size, seq_length, embed_dim)`.\n","                    - `batch_size`: The number of samples in the batch.\n","                    - `seq_length`: The number of tokens (or time steps) in each sequence.\n","                    - `embed_dim`: The dimension of the embedding for each token.\n","            \n","        \"\"\"\n","        if is_first:\n","            residual_x = x \n","            cross_x = self.crossattention(x, catx)\n","            cross_x = self.dropout1(cross_x)\n","            cross_x = cross_x + residual_x\n","            cross_x = self.norm1(cross_x)\n","            residual_x = cross_x\n","            cross_x = self.ffn(cross_x)\n","            cross_x = self.dropout2(cross_x)\n","            cross_x = cross_x + residual_x\n","            cross_x = self.norm2(cross_x)\n","            return cross_x\n","        \n","        residual_x = catx\n","        catx = self.attention(catx)\n","        catx = self.dropout1(catx)\n","        catx = catx + residual_x\n","        catx = self.norm1(catx)\n","        residual_x = catx\n","        catx = self.ffn(catx)\n","        catx = self.dropout2(catx)\n","        catx = catx + residual_x\n","        catx = self.norm2(catx)\n","        return catx   \n"," \n"]},{"cell_type":"markdown","metadata":{},"source":["## META TRANSFORMER LAYER"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T18:54:02.598154Z","iopub.status.busy":"2024-05-22T18:54:02.597280Z","iopub.status.idle":"2024-05-22T18:54:02.620116Z","shell.execute_reply":"2024-05-22T18:54:02.619054Z","shell.execute_reply.started":"2024-05-22T18:54:02.598115Z"},"trusted":true},"outputs":[],"source":["class rememBERT(nn.Module):\n","    def __init__(self, n_layers, vocab_size, embed_dim, n_heads, num_classes, attn_drop_rate, layer_drop_rate, seq_len):\n","        super().__init__()\n","        self.embed = nn.Embedding(vocab_size+1, embed_dim)\n","        self.position = PositionalEncoding(embed_dim, layer_drop_rate)\n","        self.first_layer = EncoderLayer(embed_dim, n_heads, attn_drop_rate, layer_drop_rate)\n","        self.net = nn.Sequential(*[\n","        EncoderLayer(embed_dim, n_heads, attn_drop_rate, layer_drop_rate) for _ in range(n_layers-1)\n","        ])\n","        self.pooler = nn.Sequential(OrderedDict([\n","            ('dense', nn.Linear(embed_dim, embed_dim)),\n","            ('activation', nn.Tanh()),\n","        ]))\n","        self.classifier = Classifier(embed_dim, num_classes) \n","        self.saved_sample = None\n","        self.seq_len = seq_len\n","    def forward(self, batch_text):\n","        \"\"\"\n","             Args:\n","                 batch_text (torch.Tensor): Batch of input texts represented as token indices.\n","                     Its shape should be `(batch_size, seq_length)`.\n","             Returns:\n","                 torch.Tensor: Predicted logits for each class.\n","                     It has the shape `(batch_size, num_classes)`.\n","                     - `batch_size`: The number of samples in the batch.\n","                     - `num_classes`: The number of classes in the classification task.\n","        \"\"\"\n","        if self.training:\n","            if self.saved_sample == None:\n","                    self.saved_sample = batch_text[:1]\n","            newtensor = []\n","            batch_text = batch_text.squeeze(1)\n","            for i in range(1):\n","                offset_x = torch.roll(batch_text, shifts=+i+1, dims=0)\n","            zerotensor = torch.zeros_like(batch_text[0])\n","            for i in range(len(batch_text)-1):\n","                if random.random() < 0.3:\n","                    newtensor.append(torch.cat((zerotensor,offset_x[i+1])))\n","                else:\n","                    newtensor.append(torch.cat((offset_x[i],offset_x[i+1])))\n","            newtensor.append(torch.cat((offset_x[-1],offset_x[0])))\n","            numpy_array = np.array([t.cpu().detach().numpy() for t in newtensor])\n","            newtensor = torch.Tensor(numpy_array)\n","            newtensor = newtensor.to(device).to(torch.int64)\n","            embedding = self.position(self.embed(newtensor)) \n","            extracted_tensor = embedding[:, self.seq_len:, :]\n","            embedding = self.first_layer(embedding, extracted_tensor, True) \n","        else:\n","            newtensor = []\n","            batch_text = batch_text.squeeze(1)\n","            for i in range(1):\n","                offset_xt = torch.roll(batch_text, shifts=+i+1, dims=0)\n","            for i in range(len(batch_text)-1): ## DATA LEAKAGE ?\n","                newtensor.append(torch.cat((offset_xt[i],offset_xt[i+1])))\n","            newtensor.append(torch.cat((offset_xt[-1],offset_xt[0])))\n","            newtensor = np.array([t.cpu().detach().numpy() for t in newtensor])\n","            newtensor = torch.Tensor(newtensor)\n","            newtensor = newtensor.to(device).to(torch.int64)\n","            embedding = self.position(self.embed(newtensor))\n","            textracted_tensor = embedding[:, self.seq_len:, :]\n","            embedding = self.first_layer(embedding, textracted_tensor, True)\n","\n","        new_embedding = self.net((embedding))\n","        o = self.pooler(new_embedding[:, 0])\n","        preds = self.classifier(o)\n","        return preds\n"]},{"cell_type":"markdown","metadata":{},"source":["## DATALOADER & BENCHMARK"]},{"cell_type":"markdown","metadata":{},"source":["### CHOOSE DATASET & DEFINE SEQUENCE LENGTH"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = \"asc\"\n","seq_len = 256"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T19:27:39.729211Z","iopub.status.busy":"2024-05-22T19:27:39.728754Z","iopub.status.idle":"2024-05-22T19:27:39.838059Z","shell.execute_reply":"2024-05-22T19:27:39.836875Z","shell.execute_reply.started":"2024-05-22T19:27:39.729156Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["10241\n","19\n"]}],"source":["import os\n","import json\n","\n","if(df == 'dsc'):\n","    directory = '/kaggle/input/dsc-dataset/dat/dsc/'\n","    categories = ['Kindle_Store', 'Movies_and_TV', 'Musical_Instruments', 'Office_Products', 'Patio_Lawn_and_Garden', 'Pet_Supplies', 'Sports_and_Outdoors', 'Tools_and_Home_Improvement', 'Toys_and_Games', 'Video_Games']\n","\n","    dsc_train_text = []\n","    dsc_train_labels = []\n","    for i in range(0, len(categories)):\n","        file_path = os.path.join(directory, categories[i])\n","        file_path = os.path.join(file_path, 'train.json')\n","        with open(file_path, 'r') as file:\n","            data = json.load(file)\n","            sentence_list = [value[\"sentence\"] for key, value in data.items()]\n","            labels = [i] * len(sentence_list)\n","            dsc_train_text += sentence_list\n","            dsc_train_labels += labels\n","\n","\n","    dsc_test_text = []\n","    dsc_test_labels = []\n","    for i in range(0, len(categories)):\n","        file_path = os.path.join(directory, categories[i])\n","        file_path = os.path.join(file_path, 'test.json')\n","        with open(file_path, 'r') as file:\n","            data = json.load(file)\n","            sentence_list = [value[\"sentence\"] for key, value in data.items()]\n","            labels = [i] * len(sentence_list)\n","            dsc_test_text += sentence_list\n","            dsc_test_labels += labels\n","\n","    train_text = dsc_train_text\n","    train_labels = dsc_train_labels\n","    test_text = dsc_test_text\n","    test_labels = dsc_test_labels\n","elif(df == \"news\"):\n","    dataset = load_dataset(\"setfit/20_newsgroups\")\n","    train_text = dataset['train']['text']\n","    train_labels = dataset['train']['label']\n","    test_text = dataset['test']['text']\n","    test_labels = dataset['test']['label']\n","elif(df == \"asc\"):\n","    directory3 = \"/kaggle/input/dsc-dataset/dat/absa/Bing3Domains/asc\"\n","    directory5 = \"/kaggle/input/dsc-dataset/dat/absa/Bing5Domains/asc\"\n","    directory9 = \"/kaggle/input/dsc-dataset/dat/absa/Bing9Domains/asc\"\n","    directory2 = \"/kaggle/input/dsc-dataset/dat/absa/XuSemEval/asc/14/\"\n","    \n","    categories3 = [\"Computer\", \"Router\", \"Speaker\"]\n","    categories5 = [\"ApexAD2600Progressive\", \"CanonG3\", \"CreativeLabsNomadJukeboxZenXtra40GB\", \"NikonCoolpix4300\", \"Nokia6610\"]\n","    categories9 = [\"CanonPowerShotSD500\", \"CanonS100\", \"DiaperChamp\", \"HitachiRouter\", \"LinksysRouter\", \"MicroMP3\", \"Nokia6600\", \"Norton\", \"ipod\"]\n","    categories2 = [\"laptop\"]\n","    \n","    directories = [directory3, directory5, directory9, directory2]\n","    categories = [categories3, categories5, categories9, categories2]\n","    \n","    asc_train_text = []\n","    asc_train_labels = []\n","    encoded_label = 0\n","    for i in range(0, len(directories)):\n","        for j in range(0, len(categories[i])):\n","            file_path = os.path.join(directories[i], categories[i][j])\n","            file_path = os.path.join(file_path, 'train.json')\n","            with open(file_path, 'r') as file:\n","                data = json.load(file)\n","                sentence_list = [value[\"sentence\"] for key, value in data.items()]\n","                labels = [encoded_label] * len(sentence_list)\n","                asc_train_text += sentence_list\n","                asc_train_labels += labels\n","            encoded_label += 1\n","\n","    asc_test_text = []\n","    asc_test_labels = []\n","    encoded_label = 0\n","    for i in range(0, len(directories)):\n","        for j in range(0, len(categories[i])):\n","            file_path = os.path.join(directories[i], categories[i][j])\n","            file_path = os.path.join(file_path, 'test.json')\n","            with open(file_path, 'r') as file:\n","                data = json.load(file)\n","                sentence_list = [value[\"sentence\"] for key, value in data.items()]\n","                labels = [encoded_label] * len(sentence_list)\n","                asc_test_text += sentence_list\n","                asc_test_labels += labels\n","            encoded_label += 1\n","\n","    train_text = asc_train_text\n","    train_labels = asc_train_labels\n","    test_text = asc_test_text\n","    test_labels = asc_test_labels"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T19:23:09.398849Z","iopub.status.busy":"2024-05-22T19:23:09.398514Z","iopub.status.idle":"2024-05-22T19:23:10.343692Z","shell.execute_reply":"2024-05-22T19:23:10.342644Z","shell.execute_reply.started":"2024-05-22T19:23:09.398821Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_33/4023788332.py:55: DeprecationWarning: AvalancheDataset constructor has been changed. Please check the documentation for the correct usage. You can use `avalanche.benchmarks.utils.make_classification_dataset if you need the old behavior.\n","  avl_train_data = AvalancheDataset(train_data)\n","/tmp/ipykernel_33/4023788332.py:56: DeprecationWarning: AvalancheDataset constructor has been changed. Please check the documentation for the correct usage. You can use `avalanche.benchmarks.utils.make_classification_dataset if you need the old behavior.\n","  avl_test_data = AvalancheDataset(test_data)\n"]}],"source":["class TextDataset(Dataset):\n","    def __init__(self, texts, labels):\n","        \"\"\"\n","        Args:\n","            texts (list of str): List of text samples.\n","            labels (list of int): List of labels corresponding to the text samples.\n","        \"\"\"\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    @staticmethod\n","    def preprocess_text(text):\n","        # Lowercase the text\n","        text = text.lower()\n","        # Remove URLs\n","        text = re.sub(r'http\\S+|www.\\S+', ' ', text)\n","        # Remove emails\n","        text = re.sub(r'\\S*@\\S*\\s?', ' ', text)\n","        # Remove special characters (keeping letters, numbers, and basic punctuation)\n","        text = re.sub(r'[^a-z0-9,.!? ]', ' ', text)\n","        return text\n","\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","        label = self.labels[idx]\n","\n","        # Tokenize the text (you could add truncation and padding as needed)\n","        text = TextDataset.preprocess_text(text)\n","        encoded_text = self.tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=seq_len)\n","        encoded_text = encoded_text[\"input_ids\"]\n","\n","        return encoded_text, label\n","\n","if df == \"asc\":\n","    nexp = 6\n","else:\n","    nexp = 5\n","\n","\n","train_data = TextDataset(train_text, train_labels)\n","test_data = TextDataset(test_text, test_labels)\n","\n","avl_train_data = AvalancheDataset(train_data)\n","avl_test_data = AvalancheDataset(test_data)\n","\n","\n","avl_train_data.targets = train_labels\n","avl_test_data.targets = test_labels\n","\n","benchmark = nc_benchmark(\n","    test_dataset=avl_test_data,  \n","    train_dataset=avl_train_data,\n","    n_experiences=nexp,  \n","    task_labels=False  \n",")\n","\n","train_stream = benchmark.train_stream\n","test_stream = benchmark.test_stream\n","experience = train_stream[0]\n","\n","t_label = experience.task_label\n","dataset = experience.dataset"]},{"cell_type":"markdown","metadata":{},"source":["## CONFIG"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T07:19:04.566838Z","iopub.status.busy":"2024-05-22T07:19:04.565961Z","iopub.status.idle":"2024-05-22T07:19:05.602315Z","shell.execute_reply":"2024-05-22T07:19:05.601525Z","shell.execute_reply.started":"2024-05-22T07:19:04.566801Z"},"trusted":true},"outputs":[],"source":["embed_dim = 768\n","n_heads = 4\n","n_layers = 3\n","vocab_size = 30522\n","attn_drop_rate = 0.2\n","layer_drop_rate = 0.2\n","batch_size = 32\n","if df == \"asc\":\n","    num_classes = 18\n","elif df == \"dsc\":\n","    num_classes = 10   \n","elif df == \"news\":\n","    num_classes = 20\n","else:\n","    raise Exception\n","num_epochs = 5\n","model = rememBERT(n_layers, vocab_size, embed_dim, n_heads, num_classes, attn_drop_rate, layer_drop_rate, seq_len)\n","model = model.to(device)\n","\n","def calculate_accuracy(outputs, labels):\n","    _, predicted = torch.max(outputs, dim=1)\n","    correct = (predicted == labels).sum().item()  \n","    total = labels.size(0)\n","    accuracy = correct / total\n","    predicted = predicted.detach().cpu().numpy()\n","    labels = labels.detach().cpu().numpy()\n","    f1macro = f1_score(labels, predicted, average='macro')\n","    return accuracy, f1macro, predicted, labels\n","\n","\n","\n","optimizer = AdamW(model.parameters(), lr=0.0001)\n","criterion = nn.CrossEntropyLoss()\n","torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5)"]},{"cell_type":"markdown","metadata":{},"source":["## TRAINING TESTING LOOP"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T18:54:55.495217Z","iopub.status.busy":"2024-05-22T18:54:55.494784Z","iopub.status.idle":"2024-05-22T18:54:56.334159Z","shell.execute_reply":"2024-05-22T18:54:56.332506Z","shell.execute_reply.started":"2024-05-22T18:54:55.495169Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 20\u001b[0m\n\u001b[1;32m     15\u001b[0m replay \u001b[38;5;241m=\u001b[39m ReplayPlugin(mem_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m     16\u001b[0m ewc \u001b[38;5;241m=\u001b[39m EWCPlugin(ewc_lambda\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m cl_strategy \u001b[38;5;241m=\u001b[39m SupervisedTemplate(\n\u001b[0;32m---> 20\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m, optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m     21\u001b[0m     criterion\u001b[38;5;241m=\u001b[39mcriterion, train_mb_size\u001b[38;5;241m=\u001b[39mbatch_size, train_epochs\u001b[38;5;241m=\u001b[39mnum_epochs, eval_mb_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     22\u001b[0m     evaluator\u001b[38;5;241m=\u001b[39meval_plugin,device\u001b[38;5;241m=\u001b[39mdevice,plugins\u001b[38;5;241m=\u001b[39m[replay])\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# strategy = EWC(\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#     model=model,\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#     optimizer=optimizer,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#     ewc_lambda=0.4,\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"source":["interactive_logger = InteractiveLogger()\n","loggers=[]\n","loggers.append(InteractiveLogger())\n","#loggers.append(WandBLogger(project_name=\"sequential_meta_classifier\", run_name=\"40e_0.0001lr_512dim_4h_3l_0.2adr_0.2ldr_AVL_COS\"))\n","eval_plugin = EvaluationPlugin(\n","    accuracy_metrics(\n","        minibatch=False, epoch=True, experience=True, stream=True\n","    ),\n","    confusion_matrix_metrics(num_classes=benchmark.n_classes, save_image=False,\n","                             stream=True),\n","    forgetting_metrics(experience=True, stream=True),\n","    loggers=loggers,\n",")\n","\n","replay = ReplayPlugin(mem_size=1000)\n","ewc = EWCPlugin(ewc_lambda=1)\n","\n","\n","cl_strategy = SupervisedTemplate(\n","    model=model, optimizer=optimizer,\n","    criterion=criterion, train_mb_size=batch_size, train_epochs=num_epochs, eval_mb_size=batch_size,\n","    evaluator=eval_plugin,device=device,plugins=[replay])\n","\n","\n","\n","# strategy = EWC(\n","#     model=model,\n","#     optimizer=optimizer,\n","#     criterion=criterion,\n","#     train_mb_size=batch_size,\n","#     train_epochs=num_epochs,\n","#     eval_mb_size=batch_size,\n","#     device=device,\n","#     evaluator=eval_plugin,\n","#     ewc_lambda=0.4,\n","# )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-22T07:21:18.409402Z","iopub.status.idle":"2024-05-22T07:21:18.410310Z","shell.execute_reply":"2024-05-22T07:21:18.410058Z","shell.execute_reply.started":"2024-05-22T07:21:18.410035Z"},"trusted":true},"outputs":[],"source":["for train_task in train_stream:\n","    cl_strategy.train(train_task)\n","    cl_strategy.eval(test_stream)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5059825,"sourceId":8482928,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
