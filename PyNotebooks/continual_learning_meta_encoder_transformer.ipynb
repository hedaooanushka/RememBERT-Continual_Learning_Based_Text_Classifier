{"metadata":{"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8482928,"sourceType":"datasetVersion","datasetId":5059825}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## CHOOSE DATASET","metadata":{}},{"cell_type":"code","source":"# df = [\"news\", \"asc\", \"dsc\"]\ndf = \"asc\"","metadata":{"execution":{"iopub.status.busy":"2024-05-23T19:09:38.295835Z","iopub.execute_input":"2024-05-23T19:09:38.296191Z","iopub.status.idle":"2024-05-23T19:09:38.331755Z","shell.execute_reply.started":"2024-05-23T19:09:38.296163Z","shell.execute_reply":"2024-05-23T19:09:38.330660Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## INITIALIZE LOGGER","metadata":{}},{"cell_type":"code","source":"# !pip3 install wandb","metadata":{"execution":{"iopub.status.busy":"2024-05-23T19:10:24.210621Z","iopub.execute_input":"2024-05-23T19:10:24.210980Z","iopub.status.idle":"2024-05-23T19:10:24.215381Z","shell.execute_reply.started":"2024-05-23T19:10:24.210953Z","shell.execute_reply":"2024-05-23T19:10:24.214373Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import wandb\nwandb.login(key=\"3db31cd19d063689e924d07069de6c7a1670642b\") ","metadata":{"execution":{"iopub.status.busy":"2024-05-23T19:12:01.892601Z","iopub.execute_input":"2024-05-23T19:12:01.893225Z","iopub.status.idle":"2024-05-23T19:12:05.060401Z","shell.execute_reply.started":"2024-05-23T19:12:01.893190Z","shell.execute_reply":"2024-05-23T19:12:05.059484Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"## IMPORTS","metadata":{}},{"cell_type":"code","source":"!pip3 install avalanche-lib==\"0.4.0\"","metadata":{"execution":{"iopub.status.busy":"2024-05-23T19:12:11.630459Z","iopub.execute_input":"2024-05-23T19:12:11.631676Z","iopub.status.idle":"2024-05-23T19:12:43.484934Z","shell.execute_reply.started":"2024-05-23T19:12:11.631638Z","shell.execute_reply":"2024-05-23T19:12:43.483882Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting avalanche-lib==0.4.0\n  Downloading avalanche_lib-0.4.0-py3-none-any.whl.metadata (11 kB)\nCollecting typing-extensions==4.4.0 (from avalanche-lib==0.4.0)\n  Downloading typing_extensions-4.4.0-py3-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from avalanche-lib==0.4.0) (5.9.3)\nCollecting gputil (from avalanche-lib==0.4.0)\n  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from avalanche-lib==0.4.0) (1.2.2)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from avalanche-lib==0.4.0) (3.7.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from avalanche-lib==0.4.0) (1.26.4)\nCollecting pytorchcv (from avalanche-lib==0.4.0)\n  Downloading pytorchcv-0.0.67-py2.py3-none-any.whl.metadata (133 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (from avalanche-lib==0.4.0) (0.16.6)\nRequirement already satisfied: tensorboard>=1.15 in /opt/conda/lib/python3.10/site-packages (from avalanche-lib==0.4.0) (2.15.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from avalanche-lib==0.4.0) (4.66.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from avalanche-lib==0.4.0) (2.1.2+cpu)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from avalanche-lib==0.4.0) (0.16.2+cpu)\nRequirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (from avalanche-lib==0.4.0) (1.3.2)\nCollecting gdown (from avalanche-lib==0.4.0)\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nCollecting quadprog (from avalanche-lib==0.4.0)\n  Downloading quadprog-0.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from avalanche-lib==0.4.0) (0.3.8)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from avalanche-lib==0.4.0) (21.3)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=1.15->avalanche-lib==0.4.0) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=1.15->avalanche-lib==0.4.0) (1.60.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=1.15->avalanche-lib==0.4.0) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=1.15->avalanche-lib==0.4.0) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=1.15->avalanche-lib==0.4.0) (3.5.2)\nRequirement already satisfied: protobuf<4.24,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=1.15->avalanche-lib==0.4.0) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=1.15->avalanche-lib==0.4.0) (2.31.0)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=1.15->avalanche-lib==0.4.0) (69.0.3)\nRequirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=1.15->avalanche-lib==0.4.0) (1.16.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=1.15->avalanche-lib==0.4.0) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=1.15->avalanche-lib==0.4.0) (3.0.2)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown->avalanche-lib==0.4.0) (4.12.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown->avalanche-lib==0.4.0) (3.13.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->avalanche-lib==0.4.0) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->avalanche-lib==0.4.0) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->avalanche-lib==0.4.0) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->avalanche-lib==0.4.0) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->avalanche-lib==0.4.0) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->avalanche-lib==0.4.0) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->avalanche-lib==0.4.0) (2.9.0.post0)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->avalanche-lib==0.4.0) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->avalanche-lib==0.4.0) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->avalanche-lib==0.4.0) (3.2.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->avalanche-lib==0.4.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->avalanche-lib==0.4.0) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->avalanche-lib==0.4.0) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->avalanche-lib==0.4.0) (2024.2.0)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics->avalanche-lib==0.4.0) (0.11.2)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb->avalanche-lib==0.4.0) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->avalanche-lib==0.4.0) (3.1.41)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->avalanche-lib==0.4.0) (1.45.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb->avalanche-lib==0.4.0) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb->avalanche-lib==0.4.0) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb->avalanche-lib==0.4.0) (1.3.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb->avalanche-lib==0.4.0) (1.4.4)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb->avalanche-lib==0.4.0) (4.0.11)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15->avalanche-lib==0.4.0) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15->avalanche-lib==0.4.0) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15->avalanche-lib==0.4.0) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=1.15->avalanche-lib==0.4.0) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard>=1.15->avalanche-lib==0.4.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard>=1.15->avalanche-lib==0.4.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard>=1.15->avalanche-lib==0.4.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard>=1.15->avalanche-lib==0.4.0) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard>=1.15->avalanche-lib==0.4.0) (2.1.3)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown->avalanche-lib==0.4.0) (2.5)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown->avalanche-lib==0.4.0) (1.7.1)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->avalanche-lib==0.4.0) (1.3.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->avalanche-lib==0.4.0) (5.0.1)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.15->avalanche-lib==0.4.0) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=1.15->avalanche-lib==0.4.0) (3.2.2)\nDownloading avalanche_lib-0.4.0-py3-none-any.whl (894 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m894.6/894.6 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\nDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nDownloading pytorchcv-0.0.67-py2.py3-none-any.whl (532 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.4/532.4 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading quadprog-0.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.2/508.2 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: gputil\n  Building wheel for gputil (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7393 sha256=7cd128b63df8f5d93a6cd99c2bfcf197664fd7d8586b49b09dc7c3535cb1019d\n  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\nSuccessfully built gputil\nInstalling collected packages: gputil, typing-extensions, quadprog, pytorchcv, gdown, avalanche-lib\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.9.0\n    Uninstalling typing_extensions-4.9.0:\n      Successfully uninstalled typing_extensions-4.9.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\nsqlalchemy 2.0.25 requires typing-extensions>=4.6.0, but you have typing-extensions 4.4.0 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\nfastapi 0.108.0 requires typing-extensions>=4.8.0, but you have typing-extensions 4.4.0 which is incompatible.\njupyterlab 4.1.6 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\npydantic 2.5.3 requires typing-extensions>=4.6.1, but you have typing-extensions 4.4.0 which is incompatible.\npydantic-core 2.14.6 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.4.0 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\ntypeguard 4.1.5 requires typing-extensions>=4.7.0; python_version < \"3.12\", but you have typing-extensions 4.4.0 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed avalanche-lib-0.4.0 gdown-5.2.0 gputil-1.4.0 pytorchcv-0.0.67 quadprog-0.1.12 typing-extensions-4.4.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip3 install datasets","metadata":{"execution":{"iopub.status.busy":"2024-05-23T19:12:43.486676Z","iopub.execute_input":"2024-05-23T19:12:43.487032Z","iopub.status.idle":"2024-05-23T19:12:55.813543Z","shell.execute_reply.started":"2024-05-23T19:12:43.486999Z","shell.execute_reply":"2024-05-23T19:12:55.812367Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.4.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\nimport math\nfrom collections import OrderedDict\nimport torch\nfrom torch import nn, Tensor\nfrom typing import Union, Tuple, List, Iterable, Dict\nimport torch.nn.functional as F\nfrom torch.nn.parameter import Parameter\nfrom torch.optim import AdamW\nfrom torch.utils.data import DataLoader\nimport numpy as np\nimport gzip, csv\nimport pandas as pd\nfrom tqdm.auto import tqdm\nimport torch.nn.init as init\nimport random\ntorch.manual_seed(0)\nnp.random.seed(0)\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport argparse\nimport torch\nfrom torch.nn import CrossEntropyLoss\nfrom torch.optim import AdamW\nfrom torch import nn, Tensor\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset\nfrom avalanche.benchmarks.utils import AvalancheDataset\nfrom avalanche.benchmarks.generators import nc_benchmark\nfrom transformers import BertTokenizer\nfrom datasets import load_dataset\nimport re\nfrom avalanche.benchmarks.classic import SplitMNIST\nfrom avalanche.models import MTSimpleMLP\nfrom avalanche.training.supervised import EWC\nfrom avalanche.evaluation.metrics import forgetting_metrics, accuracy_metrics\nfrom avalanche.logging import InteractiveLogger\nfrom avalanche.training.plugins import EvaluationPlugin\nfrom avalanche.evaluation.metrics import forgetting_metrics, accuracy_metrics, \\\n    loss_metrics, timing_metrics, cpu_usage_metrics, confusion_matrix_metrics, disk_usage_metrics\nfrom avalanche.training.templates import SupervisedTemplate\nfrom avalanche.training.plugins import ReplayPlugin, EWCPlugin\nfrom avalanche.logging import WandBLogger\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-05-23T19:11:46.219645Z","iopub.execute_input":"2024-05-23T19:11:46.220044Z","iopub.status.idle":"2024-05-23T19:11:50.061093Z","shell.execute_reply.started":"2024-05-23T19:11:46.220013Z","shell.execute_reply":"2024-05-23T19:11:50.059561Z"},"trusted":true},"execution_count":5,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mavalanche\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbenchmarks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AvalancheDataset\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mavalanche\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbenchmarks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nc_benchmark\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'avalanche'"],"ename":"ModuleNotFoundError","evalue":"No module named 'avalanche'","output_type":"error"}]},{"cell_type":"markdown","source":"## ACTIVATION FUNCTION","metadata":{}},{"cell_type":"code","source":"def gelu(x):\n    \"\"\"Implementation of the gelu activation function.\"\"\"\n    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T18:53:57.452787Z","iopub.execute_input":"2024-05-22T18:53:57.453573Z","iopub.status.idle":"2024-05-22T18:53:57.459768Z","shell.execute_reply.started":"2024-05-22T18:53:57.453541Z","shell.execute_reply":"2024-05-22T18:53:57.458333Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## POSTIONAL ENCODING LAYER","metadata":{}},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n\n    def __init__(self, embed_dim: int, drop_rate=0.1, max_len=5000):\n        super().__init__()\n        self.dropout = nn.Dropout(p=drop_rate)\n\n        position = torch.arange(max_len).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, embed_dim, 2) * (-math.log(10000.0) / embed_dim))\n        pe = torch.zeros(1, max_len, embed_dim)\n        pe[0, :, 0::2] = torch.sin(position * div_term)\n        pe[0, :, 1::2] = torch.cos(position * div_term)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Tensor, shape [batch_size, seq_len, embedding_dim]\n        \n        Returns:\n            torch.Tensor: Output tensor after adding positional encodings and applying dropout.\n                 It has the same shape as the input tensor [batch_size, seq_len, embedding_dim].\n                 The positional encodings are added to the input tensor along the sequence length dimension,\n                 and dropout is applied to the combined tensor.\n        \n        \"\"\"\n        x = x + self.pe[:, :x.size(1)]\n        return self.dropout(x)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T18:53:58.036086Z","iopub.execute_input":"2024-05-22T18:53:58.037034Z","iopub.status.idle":"2024-05-22T18:53:58.047263Z","shell.execute_reply.started":"2024-05-22T18:53:58.036995Z","shell.execute_reply":"2024-05-22T18:53:58.045786Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## ATTENTION MECHANISM","metadata":{}},{"cell_type":"code","source":"def scaled_dot_product(q, k, v, attn_drop_rate=0.1):\n    \"\"\"\n    Args:\n      q: query, shape: (batch, # heads, seq len, head dimension)\n      k: keys, shape: (batch, # heads, seq len, head dimension)\n      v: value, shape: (batch, # heads, seq len, head dimension)\n      attn_drop_rate: probability of an element to be zeroed,\n      mask: the optional masking of specific entries in the attention matrix.\n              shape: (batch, seq len)\n    \n     Returns:\n        torch.Tensor: Output tensor after scaled dot product attention computation.\n           Shape: (batch, # heads, seq len, head dimension).\n    \n    \"\"\"\n    d_k = q.shape[-1]\n    attn_logits = torch.matmul(q, k.transpose(-1, -2))\n    attn_logits = attn_logits/math.sqrt(d_k)\n    attention = F.softmax(attn_logits, dim=-1)\n    attention = F.dropout(attention, p=attn_drop_rate)\n    values = torch.matmul(attention,v)\n    return values","metadata":{"execution":{"iopub.status.busy":"2024-05-22T18:53:58.597927Z","iopub.execute_input":"2024-05-22T18:53:58.598367Z","iopub.status.idle":"2024-05-22T18:53:58.606770Z","shell.execute_reply.started":"2024-05-22T18:53:58.598334Z","shell.execute_reply":"2024-05-22T18:53:58.605577Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### MULTI HEAD SELF ATTENTION","metadata":{}},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self, embed_dim, n_heads, attn_drop_rate):\n        super().__init__()\n        self.embed_dim = embed_dim\n        self.n_heads = n_heads\n        self.head_dim = embed_dim // n_heads\n        self.attn_drop_rate = attn_drop_rate\n        self.query = nn.Linear(self.embed_dim, self.n_heads*self.head_dim)\n        self.key = nn.Linear(self.embed_dim, self.n_heads*self.head_dim)\n        self.value = nn.Linear(self.embed_dim, self.n_heads*self.head_dim)\n        self.o_proj = nn.Linear(self.embed_dim, self.n_heads*self.head_dim)\n        self._reset_parameters()\n\n    def _reset_parameters(self):\n      nn.init.xavier_uniform_(self.query.weight)\n      self.query.bias.data.fill_(0)\n      nn.init.xavier_uniform_(self.key.weight)\n      self.key.bias.data.fill_(0)\n      nn.init.xavier_uniform_(self.value.weight)\n      self.value.bias.data.fill_(0)\n      nn.init.xavier_uniform_(self.o_proj.weight)\n      self.o_proj.bias.data.fill_(0)\n\n    def split_heads(self, tensor):\n       new_shape = tensor.size()[:-1] + (self.n_heads, self.head_dim)\n       tensor = tensor.view(*new_shape)\n       tensor = tensor.permute(0, 2, 1, 3).contiguous()\n       return tensor\n\n    def merge_heads(self, tensor, batch_size, seq_length):\n       tensor = tensor.transpose(1, 2).contiguous().view(batch_size, seq_length, self.embed_dim)\n       return tensor\n\n    def forward(self, embedding):\n      \"\"\"\n       Args:\n        embedding (torch.Tensor): \n            A tensor of shape (batch_size, seq_length, embed_dim) representing the input embeddings.\n            - `batch_size`: The number of samples in the batch.\n            - `seq_length`: The number of tokens (or time steps) in each sequence.\n            - `embed_dim`: The dimension of the embedding for each token.\n       \n       Returns:\n        torch.Tensor: \n            A tensor of shape (batch_size, seq_length, embed_dim) representing the attended embeddings.\n            - `batch_size`: The number of samples in the batch.\n            - `seq_length`: The number of tokens (or time steps) in each sequence.\n            - `embed_dim`: The dimension of the embedding for each token.\n      \n      \"\"\"\n      batch_size, seq_length, embed_dim = embedding.size()\n      q, k, v = self.query(embedding), self.key(embedding), self.value(embedding)\n      q = self.split_heads(q)\n      k = self.split_heads(k)\n      v = self.split_heads(v)\n      values = scaled_dot_product(q, k, v, self.attn_drop_rate)\n      values = self.merge_heads(values, batch_size, seq_length)\n      attended_embeds = self.o_proj(values)\n      return attended_embeds","metadata":{"execution":{"iopub.status.busy":"2024-05-22T18:53:59.147303Z","iopub.execute_input":"2024-05-22T18:53:59.147730Z","iopub.status.idle":"2024-05-22T18:53:59.165738Z","shell.execute_reply.started":"2024-05-22T18:53:59.147695Z","shell.execute_reply":"2024-05-22T18:53:59.164414Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### MULTI HEAD CROSS ATTENTION","metadata":{}},{"cell_type":"code","source":"class MultiHeadCrossAttention(nn.Module):  \n    def __init__(self, embed_dim, n_heads, attn_drop_rate):\n        super().__init__()\n        self.embed_dim = embed_dim\n        self.n_heads = n_heads\n        self.head_dim = embed_dim // n_heads\n        self.key = nn.Linear(self.embed_dim, self.n_heads*self.head_dim)\n        self.value = nn.Linear(self.embed_dim, self.n_heads*self.head_dim)\n        self.query = nn.Linear(self.embed_dim , embed_dim)\n        self.linear_layer = nn.Linear(embed_dim, embed_dim)\n        self.attn_drop_rate = attn_drop_rate\n   \n    def forward(self, x, catx): \n         \"\"\"\n            Args:\n             catx (torch.Tensor): \n                 A tensor of shape (batch_size, seq_length, embed_dim) representing the input embeddings of orignal sequence with additional context.\n                 - `batch_size`: The number of samples in the batch.\n                 - `seq_length`: The number of tokens (or time steps) in each sequence.\n                 - `embed_dim`: The dimension of the embedding for each token.\n            \n             x (torch.Tensor): \n                 A tensor of shape (batch_size, seq_length, embed_dim) representing the input embeddings of orignal sequence.\n                 - `batch_size`: The number of samples in the batch.\n                 - `seq_length`: The number of tokens (or time steps) in each sequence.\n                 - `embed_dim`: The dimension of the embedding for each token.     \n                 \n            Returns:\n             torch.Tensor: \n                 A tensor of shape (batch_size, seq_length, embed_dim) representing the attended embeddings.\n                 - `batch_size`: The number of samples in the batch.\n                 - `seq_length`: The number of tokens (or time steps) in each sequence.\n                 - `embed_dim`: The dimension of the embedding for each token.\n        \n        \"\"\"\n         qbatch_size, qsequence_length, qembeddings = x.size()\n         batch_size, sequence_length, embeddings = catx.size()\n         q, k, v = self.query(x), self.key(catx), self.value(catx)\n         k = k.reshape(batch_size, sequence_length, self.n_heads, self.head_dim)  \n         v = v.reshape(batch_size, sequence_length, self.n_heads, self.head_dim)\n         q = q.reshape(qbatch_size, qsequence_length, self.n_heads, self.head_dim) \n         k = k.permute(0, 2, 1, 3) \n         v = v.permute(0, 2, 1, 3)\n         q = q.permute(0, 2, 1, 3) \n         values = scaled_dot_product(q, k, v, self.attn_drop_rate) \n         values = values.reshape(qbatch_size, qsequence_length, embeddings)\n         out = self.linear_layer(values)  \n         return out ","metadata":{"execution":{"iopub.status.busy":"2024-05-22T18:53:59.645317Z","iopub.execute_input":"2024-05-22T18:53:59.646499Z","iopub.status.idle":"2024-05-22T18:53:59.660337Z","shell.execute_reply.started":"2024-05-22T18:53:59.646459Z","shell.execute_reply":"2024-05-22T18:53:59.658974Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## LAYER NORMALIZATION LAYER","metadata":{}},{"cell_type":"code","source":"class LayerNormalization(nn.Module):\n    def __init__(self, parameters_shape, eps=1e-5):\n        super().__init__()\n        self.parameters_shape=parameters_shape\n        self.eps=eps\n        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n        self.beta =  nn.Parameter(torch.zeros(parameters_shape))\n\n    def forward(self, inputs):\n        \"\"\"\n         Args:\n         inputs (Tensor): Input tensor to normalize.\n         \n         Returns:\n                torch.Tensor: Normalized tensor after applying layer normalization.\n                 It has the same shape as the input tensor `(batch_size, *parameters_shape)`.\n\n        \"\"\"\n        dims = [-(i + 1) for i in range(len(self.parameters_shape))]\n        mean = inputs.mean(dim=dims, keepdim=True)\n        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n        std = (var + self.eps).sqrt()\n        y = (inputs - mean) / std\n        out = self.gamma * y  + self.beta\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-05-22T18:54:00.154076Z","iopub.execute_input":"2024-05-22T18:54:00.154542Z","iopub.status.idle":"2024-05-22T18:54:00.165238Z","shell.execute_reply.started":"2024-05-22T18:54:00.154507Z","shell.execute_reply":"2024-05-22T18:54:00.163862Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## FEEDFORWARD LAYER","metadata":{}},{"cell_type":"code","source":"class PositionwiseFeedForward(nn.Module): \n\n    def __init__(self, embed_dim, drop_prob=0.1):\n        super(PositionwiseFeedForward, self).__init__()\n        self.linear1 = nn.Linear(embed_dim, 4*embed_dim)\n        self.linear2 = nn.Linear(4*embed_dim, embed_dim)\n        self.gelu = nn.GELU()\n        self.dropout = nn.Dropout(p=drop_prob)\n\n    def forward(self, x):\n        \"\"\"\n         Args:\n             x (torch.Tensor): Input tensor to the feedforward network.\n                 Its shape should be `(batch_size, sequence_length, embed_dim)`.\n                 `batch_size` is the number of sequences in a batch,\n                 `sequence_length` is the length of each sequence,\n                 and `embed_dim` is the dimensionality of the input and output embeddings.\n     \n         Returns:\n             torch.Tensor: Output tensor of the feedforward network.\n                 It has the same shape as the input tensor `(batch_size, sequence_length, embed_dim)`.\n        \n        \"\"\"\n        x = self.linear1(x)\n        x = self.gelu(x)\n        x = self.dropout(x)\n        x = self.linear2(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-05-22T18:54:00.715785Z","iopub.execute_input":"2024-05-22T18:54:00.716259Z","iopub.status.idle":"2024-05-22T18:54:00.725582Z","shell.execute_reply.started":"2024-05-22T18:54:00.716219Z","shell.execute_reply":"2024-05-22T18:54:00.724285Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## CLASSIFIER","metadata":{}},{"cell_type":"code","source":"class Classifier(nn.Module):\n    def __init__(self, input_dim, numclasses, dropout_rate=0.1):\n        super(Classifier, self).__init__()\n        self.linear = nn.Linear(input_dim, numclasses) \n\n    def forward(self, x):\n     \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor to the classifier.\n                Its shape should be `()`.\n                `batch_size` is the number of samples in the batch,\n                and `input_dim` is the dimensionality of the input features.\n\n        Returns:\n            torch.Tensor: Output tensor representing the logits for each class.\n                It has the shape `()`.\n                `batch_size` is the number of samples in the batch,\n                and `num_classes` is the number of classes in the classification task.\n     \"\"\"\n     x = self.linear(x)\n     return x","metadata":{"execution":{"iopub.status.busy":"2024-05-22T18:54:01.331641Z","iopub.execute_input":"2024-05-22T18:54:01.332044Z","iopub.status.idle":"2024-05-22T18:54:01.339985Z","shell.execute_reply.started":"2024-05-22T18:54:01.332015Z","shell.execute_reply":"2024-05-22T18:54:01.338753Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## ENCODER LAYER","metadata":{}},{"cell_type":"code","source":"class EncoderLayer(nn.Module):\n\n    def __init__(self, embed_dim, n_heads, attn_drop_rate, layer_drop_rate):\n        super(EncoderLayer, self).__init__()\n        self.embed_dim = embed_dim\n        self.n_heads = n_heads\n        self.crossattention = MultiHeadCrossAttention(self.embed_dim, self.n_heads, attn_drop_rate)\n        self.attention = MultiHeadAttention(self.embed_dim, self.n_heads, attn_drop_rate)\n        self.norm1 = LayerNormalization(parameters_shape=[self.embed_dim])\n        self.dropout1 = nn.Dropout(p=layer_drop_rate)\n        self.ffn = PositionwiseFeedForward(self.embed_dim,layer_drop_rate)\n        self.norm2 = LayerNormalization(parameters_shape=[self.embed_dim])\n        self.dropout2 = nn.Dropout(p=layer_drop_rate)\n\n    def forward(self, catx, x=None, is_first=False):\n        \"\"\"\n            Args:\n            catx (torch.Tensor): Input tensor to the encoder layer.\n                Its shape should be `(batch_size, seq_length, embed_dim)`.\n                - `batch_size`: The number of samples in the batch.\n                - `seq_length`: The number of tokens (or time steps) in each sequence.\n                - `embed_dim`: The dimension of the embedding for each token.\n    \n            x (torch.Tensor): Input tensor to the first encoder layer.\n                Its shape should be `(batch_size, seq_length, embed_dim)`.\n                - `batch_size`: The number of samples in the batch.\n                - `seq_length`: The number of tokens (or time steps) in each sequence.\n                - `embed_dim`: The dimension of the embedding for each token.\n                \n            \n            Returns:\n                torch.Tensor: Output tensor representing the encoded representations.\n                    It has the same shape as the input tensor `(batch_size, seq_length, embed_dim)`.\n                    - `batch_size`: The number of samples in the batch.\n                    - `seq_length`: The number of tokens (or time steps) in each sequence.\n                    - `embed_dim`: The dimension of the embedding for each token.\n            \n        \"\"\"\n        if is_first:\n            residual_x = x \n            cross_x = self.crossattention(x, catx)\n            cross_x = self.dropout1(cross_x)\n            cross_x = cross_x + residual_x\n            cross_x = self.norm1(cross_x)\n            residual_x = cross_x\n            cross_x = self.ffn(cross_x)\n            cross_x = self.dropout2(cross_x)\n            cross_x = cross_x + residual_x\n            cross_x = self.norm2(cross_x)\n            return cross_x\n        \n        residual_x = catx\n        catx = self.attention(catx)\n        catx = self.dropout1(catx)\n        catx = catx + residual_x\n        catx = self.norm1(catx)\n        residual_x = catx\n        catx = self.ffn(catx)\n        catx = self.dropout2(catx)\n        catx = catx + residual_x\n        catx = self.norm2(catx)\n        return catx   \n \n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T18:54:01.940410Z","iopub.execute_input":"2024-05-22T18:54:01.940835Z","iopub.status.idle":"2024-05-22T18:54:01.955821Z","shell.execute_reply.started":"2024-05-22T18:54:01.940801Z","shell.execute_reply":"2024-05-22T18:54:01.954492Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## META TRANSFORMER LAYER","metadata":{}},{"cell_type":"code","source":"class rememBERT(nn.Module):\n    def __init__(self, n_layers, vocab_size, embed_dim, n_heads, num_classes, attn_drop_rate, layer_drop_rate):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size+1, embed_dim)\n        self.position = PositionalEncoding(embed_dim, layer_drop_rate)\n        self.first_layer = EncoderLayer(embed_dim, n_heads, attn_drop_rate, layer_drop_rate)\n        self.net = nn.Sequential(*[\n        EncoderLayer(embed_dim, n_heads, attn_drop_rate, layer_drop_rate) for _ in range(n_layers-1)\n        ])\n        self.pooler = nn.Sequential(OrderedDict([\n            ('dense', nn.Linear(embed_dim, embed_dim)),\n            ('activation', nn.Tanh()),\n        ]))\n        self.classifier = Classifier(embed_dim, num_classes) \n        self.saved_sample = None\n    def forward(self, batch_text):\n        \"\"\"\n             Args:\n                 batch_text (torch.Tensor): Batch of input texts represented as token indices.\n                     Its shape should be `(batch_size, seq_length)`.\n             Returns:\n                 torch.Tensor: Predicted logits for each class.\n                     It has the shape `(batch_size, num_classes)`.\n                     - `batch_size`: The number of samples in the batch.\n                     - `num_classes`: The number of classes in the classification task.\n        \"\"\"\n        if self.training:\n            if self.saved_sample == None:\n                    self.saved_sample = batch_text[:1]\n            newtensor = []\n            batch_text = batch_text.squeeze(1)\n            for i in range(1):\n                offset_x = torch.roll(batch_text, shifts=+i+1, dims=0)\n            zerotensor = torch.zeros_like(batch_text[0])\n            for i in range(len(batch_text)-1):\n                if random.random() < 0.3:\n                    newtensor.append(torch.cat((zerotensor,offset_x[i+1])))\n                else:\n                    newtensor.append(torch.cat((offset_x[i],offset_x[i+1])))\n            newtensor.append(torch.cat((offset_x[-1],offset_x[0])))\n            numpy_array = np.array([t.cpu().detach().numpy() for t in newtensor])\n            newtensor = torch.Tensor(numpy_array)\n            newtensor = newtensor.to(device).to(torch.int64)\n            embedding = self.position(self.embed(newtensor)) \n            extracted_tensor = embedding[:, 512:, :]\n            embedding = self.first_layer(embedding, extracted_tensor, True) \n        else:\n            newtensor = []\n            batch_text = batch_text.squeeze(1)\n            for i in range(1):\n                offset_xt = torch.roll(batch_text, shifts=+i+1, dims=0)\n            for i in range(len(batch_text)-1): ## DATA LEAKAGE ?\n                newtensor.append(torch.cat((offset_xt[i],offset_xt[i+1])))\n            newtensor.append(torch.cat((offset_xt[-1],offset_xt[0])))\n            newtensor = np.array([t.cpu().detach().numpy() for t in newtensor])\n            newtensor = torch.Tensor(newtensor)\n            newtensor = newtensor.to(device).to(torch.int64)\n            embedding = self.position(self.embed(newtensor))\n            textracted_tensor = embedding[:, 512:, :]\n            embedding = self.first_layer(embedding, textracted_tensor, True)\n\n        new_embedding = self.net((embedding))\n        o = self.pooler(new_embedding[:, 0])\n        preds = self.classifier(o)\n        return preds\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T18:54:02.597280Z","iopub.execute_input":"2024-05-22T18:54:02.598154Z","iopub.status.idle":"2024-05-22T18:54:02.620116Z","shell.execute_reply.started":"2024-05-22T18:54:02.598115Z","shell.execute_reply":"2024-05-22T18:54:02.619054Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## DATALOADER & BENCHMARK","metadata":{}},{"cell_type":"code","source":"import os\nimport json\n\nif(df == 'dsc'):\n    directory = '/kaggle/input/dsc-dataset/dat/dsc/'\n    categories = ['Kindle_Store', 'Movies_and_TV', 'Musical_Instruments', 'Office_Products', 'Patio_Lawn_and_Garden', 'Pet_Supplies', 'Sports_and_Outdoors', 'Tools_and_Home_Improvement', 'Toys_and_Games', 'Video_Games']\n\n    dsc_train_text = []\n    dsc_train_labels = []\n    for i in range(0, len(categories)):\n        file_path = os.path.join(directory, categories[i])\n        file_path = os.path.join(file_path, 'train.json')\n        with open(file_path, 'r') as file:\n            data = json.load(file)\n            sentence_list = [value[\"sentence\"] for key, value in data.items()]\n            labels = [i] * len(sentence_list)\n            dsc_train_text += sentence_list\n            dsc_train_labels += labels\n\n\n    dsc_test_text = []\n    dsc_test_labels = []\n    for i in range(0, len(categories)):\n        file_path = os.path.join(directory, categories[i])\n        file_path = os.path.join(file_path, 'test.json')\n        with open(file_path, 'r') as file:\n            data = json.load(file)\n            sentence_list = [value[\"sentence\"] for key, value in data.items()]\n            labels = [i] * len(sentence_list)\n            dsc_test_text += sentence_list\n            dsc_test_labels += labels\n\n    train_text = dsc_train_text\n    train_labels = dsc_train_labels\n    test_text = dsc_test_text\n    test_labels = dsc_test_labels\nelif(df == \"news\"):\n    dataset = load_dataset(\"setfit/20_newsgroups\")\n    train_text = dataset['train']['text']\n    train_labels = dataset['train']['label']\n    test_text = dataset['test']['text']\n    test_labels = dataset['test']['label']\nelif(df == \"asc\"):\n    directory3 = \"/kaggle/input/dsc-dataset/dat/absa/Bing3Domains/asc\"\n    directory5 = \"/kaggle/input/dsc-dataset/dat/absa/Bing5Domains/asc\"\n    directory9 = \"/kaggle/input/dsc-dataset/dat/absa/Bing9Domains/asc\"\n    directory2 = \"/kaggle/input/dsc-dataset/dat/absa/XuSemEval/asc/14/\"\n    \n    categories3 = [\"Computer\", \"Router\", \"Speaker\"]\n    categories5 = [\"ApexAD2600Progressive\", \"CanonG3\", \"CreativeLabsNomadJukeboxZenXtra40GB\", \"NikonCoolpix4300\", \"Nokia6610\"]\n    categories9 = [\"CanonPowerShotSD500\", \"CanonS100\", \"DiaperChamp\", \"HitachiRouter\", \"LinksysRouter\", \"MicroMP3\", \"Nokia6600\", \"Norton\", \"ipod\"]\n    categories2 = [\"laptop\", \"rest\"]\n    \n    directories = [directory3, directory5, directory9, directory2]\n    categories = [categories3, categories5, categories9, categories2]\n    \n    asc_train_text = []\n    asc_train_labels = []\n    encoded_label = 0\n    for i in range(0, len(directories)):\n        for j in range(0, len(categories[i])):\n            file_path = os.path.join(directories[i], categories[i][j])\n            file_path = os.path.join(file_path, 'train.json')\n            with open(file_path, 'r') as file:\n                data = json.load(file)\n                sentence_list = [value[\"sentence\"] for key, value in data.items()]\n                labels = [encoded_label] * len(sentence_list)\n                asc_train_text += sentence_list\n                asc_train_labels += labels\n            encoded_label += 1\n\n    asc_test_text = []\n    asc_test_labels = []\n    encoded_label = 0\n    for i in range(0, len(directories)):\n        for j in range(0, len(categories[i])):\n            file_path = os.path.join(directories[i], categories[i][j])\n            file_path = os.path.join(file_path, 'test.json')\n            with open(file_path, 'r') as file:\n                data = json.load(file)\n                sentence_list = [value[\"sentence\"] for key, value in data.items()]\n                labels = [encoded_label] * len(sentence_list)\n                asc_test_text += sentence_list\n                asc_test_labels += labels\n            encoded_label += 1\n\n    train_text = asc_train_text\n    train_labels = asc_train_labels\n    test_text = asc_test_text\n    test_labels = asc_test_labels","metadata":{"execution":{"iopub.status.busy":"2024-05-22T19:27:39.728754Z","iopub.execute_input":"2024-05-22T19:27:39.729211Z","iopub.status.idle":"2024-05-22T19:27:39.838059Z","shell.execute_reply.started":"2024-05-22T19:27:39.729156Z","shell.execute_reply":"2024-05-22T19:27:39.836875Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"10241\n19\n","output_type":"stream"}]},{"cell_type":"code","source":"class TextDataset(Dataset):\n    def __init__(self, texts, labels):\n        \"\"\"\n        Args:\n            texts (list of str): List of text samples.\n            labels (list of int): List of labels corresponding to the text samples.\n        \"\"\"\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n    def __len__(self):\n        return len(self.texts)\n\n    @staticmethod\n    def preprocess_text(text):\n        # Lowercase the text\n        text = text.lower()\n        # Remove URLs\n        text = re.sub(r'http\\S+|www.\\S+', ' ', text)\n        # Remove emails\n        text = re.sub(r'\\S*@\\S*\\s?', ' ', text)\n        # Remove special characters (keeping letters, numbers, and basic punctuation)\n        text = re.sub(r'[^a-z0-9,.!? ]', ' ', text)\n        return text\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n\n        # Tokenize the text (you could add truncation and padding as needed)\n        text = TextDataset.preprocess_text(text)\n        encoded_text = self.tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n        encoded_text = encoded_text[\"input_ids\"]\n\n        return encoded_text, label\n\ntrain_data = TextDataset(train_text, train_labels)\ntest_data = TextDataset(test_text, test_labels)\n\navl_train_data = AvalancheDataset(train_data)\navl_test_data = AvalancheDataset(test_data)\n\n\navl_train_data.targets = train_labels\navl_test_data.targets = test_labels\n\nbenchmark = nc_benchmark(\n    test_dataset=avl_test_data,  \n    train_dataset=avl_train_data,\n    n_experiences=5,  \n    task_labels=False  \n)\n\ntrain_stream = benchmark.train_stream\ntest_stream = benchmark.test_stream\nexperience = train_stream[0]\n\nt_label = experience.task_label\ndataset = experience.dataset","metadata":{"execution":{"iopub.status.busy":"2024-05-22T19:23:09.398514Z","iopub.execute_input":"2024-05-22T19:23:09.398849Z","iopub.status.idle":"2024-05-22T19:23:10.343692Z","shell.execute_reply.started":"2024-05-22T19:23:09.398821Z","shell.execute_reply":"2024-05-22T19:23:10.342644Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/4023788332.py:55: DeprecationWarning: AvalancheDataset constructor has been changed. Please check the documentation for the correct usage. You can use `avalanche.benchmarks.utils.make_classification_dataset if you need the old behavior.\n  avl_train_data = AvalancheDataset(train_data)\n/tmp/ipykernel_33/4023788332.py:56: DeprecationWarning: AvalancheDataset constructor has been changed. Please check the documentation for the correct usage. You can use `avalanche.benchmarks.utils.make_classification_dataset if you need the old behavior.\n  avl_test_data = AvalancheDataset(test_data)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## CONFIG","metadata":{}},{"cell_type":"code","source":"embed_dim = 768\nn_heads = 4\nn_layers = 3\nvocab_size = 30522\nattn_drop_rate = 0.2\nlayer_drop_rate = 0.2\nbatch_size = 32\nnum_classes=20\nnum_epochs = 5\nmodel = rememBERT(n_layers, vocab_size, embed_dim, n_heads, num_classes, attn_drop_rate, layer_drop_rate)\nmodel = model.to(device)\n\ndef calculate_accuracy(outputs, labels):\n    _, predicted = torch.max(outputs, dim=1)\n    correct = (predicted == labels).sum().item()  \n    total = labels.size(0) \n    accuracy = correct / total\n    return accuracy\n\n\noptimizer = AdamW(model.parameters(), lr=0.0001)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T07:19:04.565961Z","iopub.execute_input":"2024-05-22T07:19:04.566838Z","iopub.status.idle":"2024-05-22T07:19:05.602315Z","shell.execute_reply.started":"2024-05-22T07:19:04.566801Z","shell.execute_reply":"2024-05-22T07:19:05.601525Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## TRAINING TESTING LOOP","metadata":{}},{"cell_type":"code","source":"interactive_logger = InteractiveLogger()\nloggers=[]\nloggers.append(InteractiveLogger())\n# loggers.append(WandBLogger(project_name=\"sequential_meta_classifier\", run_name=\"40e_0.0001lr_512dim_4h_3l_0.2adr_0.2ldr_AVL_COS\"))\neval_plugin = EvaluationPlugin(\n    accuracy_metrics(\n        minibatch=False, epoch=True, experience=True, stream=True\n    ),\n    confusion_matrix_metrics(num_classes=benchmark.n_classes, save_image=False,\n                             stream=True),\n    forgetting_metrics(experience=True, stream=True),\n    loggers=loggers,\n)\n\nreplay = ReplayPlugin(mem_size=1000)\newc = EWCPlugin(ewc_lambda=1)\n\n\ncl_strategy = SupervisedTemplate(\n    model=model, optimizer=optimizer,\n    criterion=criterion, train_mb_size=batch_size, train_epochs=num_epochs, eval_mb_size=batch_size,\n    evaluator=eval_plugin,device=device,plugins=[replay])\n\n\n\n# strategy = EWC(\n#     model=model,\n#     optimizer=optimizer,\n#     criterion=criterion,\n#     train_mb_size=batch_size,\n#     train_epochs=num_epochs,\n#     eval_mb_size=batch_size,\n#     device=device,\n#     evaluator=eval_plugin,\n#     ewc_lambda=0.4,\n# )","metadata":{"execution":{"iopub.status.busy":"2024-05-22T18:54:55.494784Z","iopub.execute_input":"2024-05-22T18:54:55.495217Z","iopub.status.idle":"2024-05-22T18:54:56.334159Z","shell.execute_reply.started":"2024-05-22T18:54:55.495169Z","shell.execute_reply":"2024-05-22T18:54:56.332506Z"},"trusted":true},"execution_count":21,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 20\u001b[0m\n\u001b[1;32m     15\u001b[0m replay \u001b[38;5;241m=\u001b[39m ReplayPlugin(mem_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m     16\u001b[0m ewc \u001b[38;5;241m=\u001b[39m EWCPlugin(ewc_lambda\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m cl_strategy \u001b[38;5;241m=\u001b[39m SupervisedTemplate(\n\u001b[0;32m---> 20\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m, optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m     21\u001b[0m     criterion\u001b[38;5;241m=\u001b[39mcriterion, train_mb_size\u001b[38;5;241m=\u001b[39mbatch_size, train_epochs\u001b[38;5;241m=\u001b[39mnum_epochs, eval_mb_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     22\u001b[0m     evaluator\u001b[38;5;241m=\u001b[39meval_plugin,device\u001b[38;5;241m=\u001b[39mdevice,plugins\u001b[38;5;241m=\u001b[39m[replay])\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# strategy = EWC(\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#     model=model,\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#     optimizer=optimizer,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#     ewc_lambda=0.4,\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}]},{"cell_type":"code","source":"for train_task in train_stream:\n    cl_strategy.train(train_task)\n    cl_strategy.eval(test_stream)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T07:21:18.409402Z","iopub.status.idle":"2024-05-22T07:21:18.410310Z","shell.execute_reply.started":"2024-05-22T07:21:18.410035Z","shell.execute_reply":"2024-05-22T07:21:18.410058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}